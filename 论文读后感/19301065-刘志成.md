# 对于谷歌三驾马车的部分理解
学号：19301065

姓名：刘志成

## 01 &nbsp;  Google File System
**GFS 的主要需求**

在学习 GFS 的原理前，首先我们应当了解 GFS 在设计时所面对的需求场景。简单概括，GFS 的设计主要基于以下几个需求：

* 节点失效是常态。系统会构建在大量的普通机器上，这使得节点失效的可能性很高。因此，GFS 必须能有较高的容错性、能够持续地监控自身的状态，同时还要能够顺畅地从节点失效中快速恢复
* 存储内容以大文件为主。系统需要存储的内容在通常情况下由数量不多的大文件构成，每个文件通常有几百 MB 甚至是几 GB 的大小；系统应当支持小文件，但不需要为其做出优化
* 主要负载为大容量连续读、小容量随机读以及追加式的连续写
* 系统应当支持高效且原子的文件追加操作，源于在 Google 的情境中，这些文件多用于生产者-消费者模式或是多路归并当需要做出取舍时，系统应选择高数据吞吐量而不是低延时

**数据一致性**

用户在使用 GFS 这类数据存储系统时，首先应当了解其所能提供的数据一致性，而作为学习者我们也应先理解 GFS 对外呈现的数据一致性功能。

首先，命名空间完全由单节点 Master 管理在其内存中，这部分数据的修改可以通过让 Master 为其添加互斥锁来解决并发修改的问题，因此命名空间的数据修改是可以确保完全原子的。

文件的数据修改则相对复杂。在讲述接下来的内容前，首先我们先明确，在文件的某一部分被修改后，它可能进入以下三种状态的其中之一：

* 客户端读取不同的 Replica 时可能会读取到不同的内容，那这部分文件是不一致的（Inconsistent）
* 所有客户端无论读取哪个 Replica 都会读取到相同的内容，那这部分文件就是一致的（Consistent）
* 所有客户端都能看到上一次修改的所有完整内容，且这部分文件是一致的，那么我们说这部分文件是确定的（Defined）
在修改后，一个文件的当前状态将取决于此次修改的类型以及修改是否成功。具体来说：

* 如果一次写入操作成功且没有与其他并发的写入操作发生重叠，那这部分的文件是确定的（同时也是一致的）
* 如果有若干个写入操作并发地执行成功，那么这部分文件会是一致的但会是不确定的：在这种情况下，客户端所能看到的数据通常不能直接体现出其中的任何一次修改
* 失败的写入操作会让文件进入不一致的状态

**数据完整性**

为了保证数据完整，Chunk Server会以校验和的形式来检测自己保存的数据是否有损坏；在侦测到损坏数据后，Chunk Server 也可以利用其它 Replica 来恢复数据。

首先，Chunk Server 会把每个 Chunk Replica 切分为若干个 64KB 大小的块，并为每个块计算 32 位校验和。和 Master 的元数据一样，这些校验和会被保存在 Chunk Server 的内存中，每次修改前都会用先写日志的形式来保证可用。当 Chunk Server 接收到读请求时，Chunk Server 首先会利用校验和检查所需读取的数据是否有发生损坏，如此一来 Chunk Server 便不会把损坏的数据传递给其他请求发送者，无论它是客户端还是另一个 Chunk Server。发现损坏后，Chunk Server 会为请求发送者发送一个错误，并向 Master 告知数据损坏事件。接收到错误后，请求发送者会选择另一个 Chunk Server 重新发起请求，而 Master 则会利用另一个 Replica 为该 Chunk 进行重备份。当新的 Replica 创建完成后，Master 便会通知该 Chunk Server 删除这个损坏的 Replica。
## 02 Google MapReduce
**MapReduce（分布式计算系统）定义：**

MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。
顾名思义，把Map和Reduce分开，它实现的主要思想也是依赖于Map(映射)和Reduce（归约）。

Map函数是一个处理key/value键值对的数据集合的过程，Reduce函数则是一个合并的过程。
Map其实就是一个映射函数，我就把它当作JAVA中的HashMap的实现原理那样理解，因为它们都是以键值对（key and value）的形式存储和处理数据。
Reduce（归约），一开始我以为归约就是合并所有具有相同key值的value值（也就是合并重复数据的过程，但并不是去除，而是合并。）

**容错处理**

***Worker失效***

MapReduce的Master节点会周期地向每一个Worker 发送 Ping信号（为什么不设计成Worker汇报机制？）。如果某个Worker一段时间内没有响应，Master 就会认为Worker已经不可用。

对于失效Worker，任何分配给该 Worker 的 Map 任务，无论是正在运行还是已经完成，都需要由 Master 重新分配给其他 Worker，因为该 Worker 不可用也意味着存储在该 Worker 本地磁盘上的中间结果亦无法访问。同时，Master 也会将这次重试通知给所有 Reducer，Reducer 会开始从新的 Mapper 上获取数据。

同时，Master 则会将Worker上未完成的Reduce任务分配给其他 Worker。鉴于 Google MapReduce 的结果是存储在 Google File System 上的，GFS保证了已完成任务的数据的可用性。

***Master 失效***

整个 MapReduce 集群中只有一个 Master 节点，MapReduce 使用Chubby来提高服务的可用性。

Master在运行时会周期性地将集群的当前状态作为保存点（Checkpoint）写入到磁盘（GFS？）中。Master 退出后，重新启动的 Master 进程即可利用存储在磁盘中的数据恢复到上一次保存点的状态。

***Worker落后***

如果某个 Worker 花了特别长的时间来完成最后的几个 Map 或 Reduce 任务，整个 MapReduce 计算任务的耗时就会因此被拉长，这样的 Worker 称为落后者（Straggler）。

MapReduce 在整个计算完成到一定程度时（何时？）就会将剩余的任务进行冗余：即同时将其分配给其他空闲 Worker 来执行，并在其中一个 Worker 完成后将该任务视作已完成。

## 03 Google BigTable
BigTable是谷歌设计的数据存储系统，它是全球化的、分布式的、持久化存储的、多维度排序的(数个层级)、可以被部署在几千台计算机上用来处理海量数据的一种非关系型的数据库。

**Bigtable特点**

适用性广泛（全谷歌平台）、可扩展（大量数据）、高效处理性能和高可靠性。Bigtable广泛使用于谷歌的产品，适应谷歌不同平台不同的要求，可以适应大量数据快速处理，可以把数据快速输送给大量用户，可以在一台或者几台大型服务器使用，也可以在几千台小计算机配置。Bigtable在很多方面和数据库很类似，很多数据库功能它都可以实现，但是它以不同于数据库的方式在连接。

**bigtable的数据模型是的一个松散的/分布式/持久存储/多维有序map，map通过row key/column key/timestamp进行排序，map的K-V可以为任意字符串。**

* row key（第一索引）可以为任意字符串，长度可以支持到64K，但是实际应用中，通常row key的值在100字节左右。可以通过row key获取当前行的任意数据。bigtable通过字节的字典顺序对数据进行存储，table将通过根据row key的区间进行分区，每个分区为一个“tablet”，tablet是bigtable进行分布式存储/负载均衡的基本数据单元。所以，读取一个小区间的数据将是高效的（只需要访问少数机器即可），所以对于row key值的设定将显得很重要，对于业务类型一样的数据，其row key值应该比较“接近”（字典顺序接近），可以让它们的存储更加集中，提高read的性能。

* column family：简单来说，column key的集合，就是一个family，中文为列族(簇?)。列族是数据操作的基本单元。Column family必须在使用之前定义。不过bigtable的设计意图是希望用户的family尽量的少，且不能在操作是修改column family。。不过一个table可以有任意多个column。Column family的名字必须是可打印字符。存储层的控制（disk，memory）均是在column family层面。

* timestamp:任何cell都可以包含多个版本的数据，这些版本数据将通过timestamp进行索引，bigtable中timestamp是64位的Long值，它可以被bigtable自动生成，也可以客户端指定。为了避免冲突，请制定唯一的timestamp。cell数据按照timestamp倒序存储，这样可以确保最新的值被优先取到。客户端可以指定（配置）任何cell需要保留version的个数，在bigtable 执行GC时，只有最新的version会被保留（同时支持最近n天内的version被保留）。















